{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:26:56.534925Z",
     "iopub.status.busy": "2025-06-19T20:26:56.534554Z",
     "iopub.status.idle": "2025-06-19T20:26:59.930314Z",
     "shell.execute_reply": "2025-06-19T20:26:59.929334Z",
     "shell.execute_reply.started": "2025-06-19T20:26:56.534900Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (100, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006270</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.872746</td>\n",
       "      <td>-2.191242</td>\n",
       "      <td>-0.474163</td>\n",
       "      <td>-0.323046</td>\n",
       "      <td>0.014688</td>\n",
       "      <td>-0.002484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.989982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.349537</td>\n",
       "      <td>-1.704709</td>\n",
       "      <td>0.068058</td>\n",
       "      <td>0.028432</td>\n",
       "      <td>0.193794</td>\n",
       "      <td>0.138212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.151877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023970</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.256156</td>\n",
       "      <td>0.806463</td>\n",
       "      <td>0.400221</td>\n",
       "      <td>-0.614188</td>\n",
       "      <td>-0.354800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.448261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.174378</td>\n",
       "      <td>0.344640</td>\n",
       "      <td>0.066872</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>-1.006373</td>\n",
       "      <td>-0.676458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.508206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002604</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>-0.161518</td>\n",
       "      <td>-0.128149</td>\n",
       "      <td>-0.195006</td>\n",
       "      <td>-0.143780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.683018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       resp  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0  0.006270          1  -1.872746  -2.191242  -0.474163  -0.323046   0.014688   \n",
       "1 -0.009792         -1  -1.349537  -1.704709   0.068058   0.028432   0.193794   \n",
       "2  0.023970         -1   0.812780  -0.256156   0.806463   0.400221  -0.614188   \n",
       "3 -0.003200         -1   1.174378   0.344640   0.066872   0.009357  -1.006373   \n",
       "4 -0.002604          1  -3.172026  -3.093182  -0.161518  -0.128149  -0.195006   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  \n",
       "0  -0.002484        NaN        NaN  -0.989982  \n",
       "1   0.138212        NaN        NaN  -0.151877  \n",
       "2  -0.354800        NaN        NaN   5.448261  \n",
       "3  -0.676458        NaN        NaN   4.508206  \n",
       "4  -0.143780        NaN        NaN   2.683018  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load a sample of the dataset (first 10 features + 'resp')\n",
    "df = pd.read_parquet(\n",
    "    \"../data/jane_street_train.parquet\",\n",
    "    columns=[\"resp\"] + [f\"feature_{i}\" for i in range(10)]  # start small\n",
    ")\n",
    "\n",
    "# For safety: work with just the first 100k rows for now\n",
    "df = df.iloc[:100].copy()\n",
    "\n",
    "print(f\"Loaded shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:26:59.932308Z",
     "iopub.status.busy": "2025-06-19T20:26:59.931676Z",
     "iopub.status.idle": "2025-06-19T20:27:00.072707Z",
     "shell.execute_reply": "2025-06-19T20:27:00.071731Z",
     "shell.execute_reply.started": "2025-06-19T20:26:59.932263Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   resp       100 non-null    float64\n",
      " 1   feature_0  100 non-null    int64  \n",
      " 2   feature_1  100 non-null    float64\n",
      " 3   feature_2  100 non-null    float64\n",
      " 4   feature_3  100 non-null    float64\n",
      " 5   feature_4  100 non-null    float64\n",
      " 6   feature_5  100 non-null    float64\n",
      " 7   feature_6  100 non-null    float64\n",
      " 8   feature_7  0 non-null      float64\n",
      " 9   feature_8  0 non-null      float64\n",
      " 10  feature_9  100 non-null    float64\n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 8.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "resp         0\n",
       "feature_0    0\n",
       "feature_1    0\n",
       "feature_2    0\n",
       "feature_3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.isna().sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:27:00.074352Z",
     "iopub.status.busy": "2025-06-19T20:27:00.073768Z",
     "iopub.status.idle": "2025-06-19T20:27:00.081568Z",
     "shell.execute_reply": "2025-06-19T20:27:00.080367Z",
     "shell.execute_reply.started": "2025-06-19T20:27:00.074326Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def frac_diff_ffd(series, d=0.5, thresh=1e-3):\n",
    "    \"\"\"\n",
    "    Apply fixed-width fractional differentiation (FFD) to a time series.\n",
    "    Parameters:\n",
    "        - series: pd.Series\n",
    "        - d: float, differentiation order\n",
    "        - thresh: float, minimum weight threshold to truncate window\n",
    "    Returns:\n",
    "        - np.array with FFD values (NaNs at the beginning)\n",
    "    \"\"\"\n",
    "    # Compute weights\n",
    "    w = [1.0]\n",
    "    k = 1\n",
    "    while True:\n",
    "        w_ = -w[-1] * (d - k + 1) / k\n",
    "        if abs(w_) < thresh:\n",
    "            break\n",
    "        w.append(w_)\n",
    "        k += 1\n",
    "    w = np.array(w[::-1])\n",
    "    \n",
    "    # Apply weights\n",
    "    width = len(w)\n",
    "    output = np.full(series.shape, np.nan)\n",
    "    for i in range(width - 1, len(series)):\n",
    "        output[i] = np.dot(w, series.values[i - width + 1:i + 1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:27:00.083481Z",
     "iopub.status.busy": "2025-06-19T20:27:00.082738Z",
     "iopub.status.idle": "2025-06-19T20:27:02.555676Z",
     "shell.execute_reply": "2025-06-19T20:27:02.554679Z",
     "shell.execute_reply.started": "2025-06-19T20:27:00.083441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [feature_0, feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7, feature_8, feature_9, resp]\n",
      "Index: []\n",
      "FFD applied. Final shape: (0, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>resp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feature_0, feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7, feature_8, feature_9, resp]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose your features and FFD parameters\n",
    "feature_cols = [col for col in df.columns if col.startswith(\"feature_\")]\n",
    "d = 0.5     # order of differentiation\n",
    "tau = 1e-3  # truncation threshold\n",
    "\n",
    "# Apply FFD to each feature\n",
    "ffd_transformed = {}\n",
    "for col in feature_cols:\n",
    "    ffd_transformed[col] = frac_diff_ffd(df[col], d=d, thresh=tau)\n",
    "\n",
    "\n",
    "print(ffd_df.head())\n",
    "# Create new DataFrame with FFD features\n",
    "ffd_df = pd.DataFrame(ffd_transformed, index=df.index)\n",
    "ffd_df[\"resp\"] = df[\"resp\"]\n",
    "\n",
    "# Drop rows with NaNs (caused by initial lag)\n",
    "ffd_df.dropna(inplace=True)\n",
    "\n",
    "print(f\"FFD applied. Final shape: {ffd_df.shape}\")\n",
    "ffd_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:27:02.556630Z",
     "iopub.status.busy": "2025-06-19T20:27:02.556356Z",
     "iopub.status.idle": "2025-06-19T20:27:02.598684Z",
     "shell.execute_reply": "2025-06-19T20:27:02.597382Z",
     "shell.execute_reply.started": "2025-06-19T20:27:02.556607Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp</th>\n",
       "      <th>resp_vol_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [resp, resp_vol_scaled]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute rolling volatility of resp\n",
    "vol_window = 100  # lookback size\n",
    "vol = ffd_df[\"resp\"].rolling(window=vol_window, min_periods=10).std()\n",
    "\n",
    "# Scale resp\n",
    "ffd_df[\"resp_vol_scaled\"] = ffd_df[\"resp\"] / vol\n",
    "\n",
    "# Drop rows with NaNs from rolling window\n",
    "ffd_df.dropna(subset=[\"resp_vol_scaled\"], inplace=True)\n",
    "\n",
    "ffd_df[[\"resp\", \"resp_vol_scaled\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:27:02.601392Z",
     "iopub.status.busy": "2025-06-19T20:27:02.601118Z",
     "iopub.status.idle": "2025-06-19T20:27:02.655473Z",
     "shell.execute_reply": "2025-06-19T20:27:02.654540Z",
     "shell.execute_reply.started": "2025-06-19T20:27:02.601371Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data shape: (0, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_vol_scaled</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [resp_vol_scaled, weight]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use inverse volatility as sample weight (proxy for uniqueness)\n",
    "ffd_df[\"weight\"] = 1.0 / vol\n",
    "ffd_df[\"weight\"] = ffd_df[\"weight\"].clip(upper=10)  # cap extreme weights\n",
    "\n",
    "# Final cleaned data\n",
    "ffd_df.dropna(inplace=True)\n",
    "print(\"Final data shape:\", ffd_df.shape)\n",
    "ffd_df[[\"resp_vol_scaled\", \"weight\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:27:02.656858Z",
     "iopub.status.busy": "2025-06-19T20:27:02.656556Z",
     "iopub.status.idle": "2025-06-19T20:27:40.844261Z",
     "shell.execute_reply": "2025-06-19T20:27:40.843139Z",
     "shell.execute_reply.started": "2025-06-19T20:27:02.656834Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Collected 0 window samples safely (not stacked)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "n_steps = 60\n",
    "n_samples = 20_000  # Even smaller sample for now\n",
    "feature_cols = [col for col in ffd_df.columns if col.startswith(\"feature_\")]\n",
    "\n",
    "valid_indices = range(n_steps, len(ffd_df))\n",
    "sampled_indices = random.sample(valid_indices, min(n_samples, len(valid_indices)))\n",
    "\n",
    "# Keep as lists for now (don't stack yet)\n",
    "X, y, w = [], [], []\n",
    "\n",
    "for i in sampled_indices:\n",
    "    X.append(ffd_df[feature_cols].iloc[i - n_steps:i].values.astype(np.float32))\n",
    "    y.append(float(ffd_df[\"resp_vol_scaled\"].iloc[i]))\n",
    "    w.append(float(ffd_df[\"weight\"].iloc[i]))\n",
    "\n",
    "print(f\"✅ Collected {len(X)} window samples safely (not stacked)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:29:28.356544Z",
     "iopub.status.busy": "2025-06-19T20:29:28.355403Z",
     "iopub.status.idle": "2025-06-19T20:29:34.988348Z",
     "shell.execute_reply": "2025-06-19T20:29:34.987375Z",
     "shell.execute_reply.started": "2025-06-19T20:29:28.356478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class JaneStreetDataset(Dataset):\n",
    "    def __init__(self, X, y, w):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_tensor = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        w_tensor = torch.tensor(self.w[idx], dtype=torch.float32)\n",
    "        return x_tensor, y_tensor, w_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:29:54.925837Z",
     "iopub.status.busy": "2025-06-19T20:29:54.924502Z",
     "iopub.status.idle": "2025-06-19T20:29:55.022801Z",
     "shell.execute_reply": "2025-06-19T20:29:55.021254Z",
     "shell.execute_reply.started": "2025-06-19T20:29:54.925800Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m dataset = JaneStreetDataset(X, y, w)\n\u001b[32m      4\u001b[39m X\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m dataloader = \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Quick test\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb, wb \u001b[38;5;129;01min\u001b[39;00m dataloader:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programming/HAW/Semester/Semester 4/ML2/Praktika/project/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:350\u001b[39m, in \u001b[36mDataLoader.__init__\u001b[39m\u001b[34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m         sampler = \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    351\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    352\u001b[39m         sampler = SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programming/HAW/Semester/Semester 4/ML2/Praktika/project/.venv/lib/python3.12/site-packages/torch/utils/data/sampler.py:143\u001b[39m, in \u001b[36mRandomSampler.__init__\u001b[39m\u001b[34m(self, data_source, replacement, num_samples, generator)\u001b[39m\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.replacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_samples <= \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # safe for Kaggle memory\n",
    "\n",
    "dataset = JaneStreetDataset(X, y, w)\n",
    "X\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Quick test\n",
    "for xb, yb, wb in dataloader:\n",
    "    print(\"Batch shapes:\", xb.shape, yb.shape, wb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:31:08.692810Z",
     "iopub.status.busy": "2025-06-19T20:31:08.692406Z",
     "iopub.status.idle": "2025-06-19T20:31:08.700986Z",
     "shell.execute_reply": "2025-06-19T20:31:08.699848Z",
     "shell.execute_reply.started": "2025-06-19T20:31:08.692786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TransformerRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, n_steps, d_model=64, nhead=4, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=128,\n",
    "            dropout=dropout,\n",
    "            batch_first=True  # Important: set True so input shape is (B, T, D)\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.head = nn.Linear(d_model, 1)  # Regression output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)               # (B, T, d_model)\n",
    "        x = self.transformer(x)             # (B, T, d_model)\n",
    "        x = x.mean(dim=1)                   # global average pooling across time\n",
    "        out = self.head(x).squeeze(-1)      # final output (B,)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:31:23.436384Z",
     "iopub.status.busy": "2025-06-19T20:31:23.435564Z",
     "iopub.status.idle": "2025-06-19T20:31:23.459626Z",
     "shell.execute_reply": "2025-06-19T20:31:23.458349Z",
     "shell.execute_reply.started": "2025-06-19T20:31:23.436353Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m n_features = \u001b[38;5;28mlen\u001b[39m(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[32m0\u001b[39m])  \u001b[38;5;66;03m# inferred from a single window\u001b[39;00m\n\u001b[32m      4\u001b[39m model = TransformerRegressor(input_dim=n_features, n_steps=n_steps).to(device)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel ready on\u001b[39m\u001b[33m\"\u001b[39m, device)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_features = len(X[0][0])  # inferred from a single window\n",
    "model = TransformerRegressor(input_dim=n_features, n_steps=n_steps).to(device)\n",
    "print(\"Model ready on\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:32:58.328158Z",
     "iopub.status.busy": "2025-06-19T20:32:58.327743Z",
     "iopub.status.idle": "2025-06-19T20:33:02.352652Z",
     "shell.execute_reply": "2025-06-19T20:33:02.351387Z",
     "shell.execute_reply.started": "2025-06-19T20:32:58.328128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def weighted_mse_loss(preds, targets, weights):\n",
    "    return torch.mean(weights * (preds - targets) ** 2)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:33:19.007207Z",
     "iopub.status.busy": "2025-06-19T20:33:19.006384Z",
     "iopub.status.idle": "2025-06-19T20:33:19.014128Z",
     "shell.execute_reply": "2025-06-19T20:33:19.012928Z",
     "shell.execute_reply.started": "2025-06-19T20:33:19.007174Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataloader, optimizer, device, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for xb, yb, wb in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            xb, yb, wb = xb.to(device), yb.to(device), wb.to(device)\n",
    "\n",
    "            preds = model(xb)\n",
    "            loss = weighted_mse_loss(preds, yb, wb)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * len(xb)\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        print(f\"Epoch {epoch+1} - Avg Loss: {avg_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T20:33:30.790286Z",
     "iopub.status.busy": "2025-06-19T20:33:30.789926Z",
     "iopub.status.idle": "2025-06-19T20:35:17.694115Z",
     "shell.execute_reply": "2025-06-19T20:35:17.693146Z",
     "shell.execute_reply.started": "2025-06-19T20:33:30.790259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 313/313 [00:21<00:00, 14.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Avg Loss: 10.433811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 313/313 [00:21<00:00, 14.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Avg Loss: 10.355791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 313/313 [00:21<00:00, 14.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Avg Loss: 10.327574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 313/313 [00:20<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Avg Loss: 10.316434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 313/313 [00:21<00:00, 14.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Avg Loss: 10.302765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, dataloader, optimizer, device, epochs=5)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 995156,
     "sourceId": 1679642,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
